* 机器学习
  KNN 算法中的问题：
  1) K 的取值
  2) K != n|c|, c 时候种类数
  3) 权重的选择，高斯衰减
  4) voronoi 空间结构

* 高斯衰减
  + [[https://www.cnblogs.com/bigmonkey/p/7387943.html][k最邻近算法——加权kNN - 我是8位的 - 博客园]]

* 算法步骤
  1. 确定模型和算法集
  2. 确定较好的部分算法
  3. 使用这些算法进行训练测试，从中选择效果最好的算法

* ravel & T
  #+BEGIN_SRC python
    >>> arr = np.full((10, 1), 1)
    >>> arr
    array([[1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1],
           [1]])
    >>> arr.T
    array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])
    >>> arr.ravel()
    array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])
  #+END_SRC

* 向量
  列或行数目为 1
* KNN
  + 高斯衰减
  + 交叉验证
  + 数据集范围的缩小
  + [[https://www.jianshu.com/p/48d391dab189][KNN算法实现及其交叉验证 - 简书]]
  + [[https://www.cnblogs.com/bigmonkey/p/7387943.html][k最邻近算法——加权kNN - 我是8位的 - 博客园]]
  + [[https://www.jianshu.com/p/0feba11bcf82][十折交叉验证 - 简书]]
  + [[https://www.cnblogs.com/itdyb/p/5735911.html][Python合并两个numpy矩阵 - 波比12 - 博客园]]

* com
  + 标称型数据
  + 信息论

* 决策树
  信息熵 -> 条件熵 -> 互信息 -> 相关性

  ID3 等算法缺陷

  协程。

  + [[https://www.cnblogs.com/pinard/p/6053344.html][决策树算法原理(下) - 刘建平Pinard - 博客园]]
  + [[https://blog.csdn.net/zjsghww/article/details/51638126][C4.5算法详解（非常仔细） - 张张的专栏 - CSDN博客]]
  + [[https://www.cnblogs.com/pinard/p/6053344.html][决策树算法原理(下) - 刘建平Pinard - 博客园]]

* 技巧
  + 集成学习，通过多个算法分类，按结果中多的算数
  + log 的使用，避免溢出，还可以将乘法变为加法 log(AB) = log(A) + log(B)

* 贝叶斯
  + [[https://www.cnblogs.com/leoo2sk/archive/2010/09/17/naive-bayesian-classifier.html][算法杂货铺——分类算法之朴素贝叶斯分类(Naive Bayesian classification) - T2噬菌体 - 博客园]]

